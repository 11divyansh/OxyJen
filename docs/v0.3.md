## Oxyjen v0.3 Documentation

**Version:** 0.3.0  
**Status:** In Development  
**Focus:** Structured Intelligence — Prompts, Schemas, Reliable Outputs  

---

## Overview

Oxyjen v0.3 introduces structured intelligence to Java AI pipelines.

Instead of unpredictable text, you can now enforce JSON schemas, validate model output, and automatically retry until the structure is correct.

At the core:

- Prompt templates for reusable prompts
- JSON schemas for structured outputs
- Automatic validation + retry
- SchemaNode for graph integration

---

## What v0.3 Solves

### Before v0.3

```java
String response = model.chat("Extract person info: John Smith, age 30");
// Could be anything:
// "John Smith is 30"
// "{ name: John }"
// invalid JSON
// random formats
```
### With v0.3
```java
JSONSchema schema = JSONSchema.object()
    .property("name", PropertySchema.string("Person name"))
    .property("age", PropertySchema.number("Person age"))
    .required("name", "age")
    .build();

SchemaEnforcer enforcer = new SchemaEnforcer(model, schema);

String json = enforcer.execute(
    "Extract person info: John Smith, age 30"
);

// Always valid JSON:
// {"name":"John Smith","age":30}
```
---

Core Concepts

**Prompt Templates**
- Prompt templates let you define prompts with variables and fill them at runtime.

**Basic Usage**
```java
PromptTemplate template = PromptTemplate.of(
    "Hello {{name}}, you are {{age}} years old."
);

String result = template.render(
    "name", "Alice",
    "age", 25
);
```
**Required / Optional Variables**
```java
PromptTemplate template = PromptTemplate.of(
    "Hello {{name}}, role: {{role}}",
    Variable.required("name"),
    Variable.optional("role", "guest")
);

// Uses default role
template.render("name", "Alice");

// Override default
template.render("name", "Bob", "role", "admin");
```
Variables are provided at execution time, not on nodes.

**JSON Schema**
JSONSchema defines the structure your LLM output must follow.

***Creating a Schema***
```java
JSONSchema schema = JSONSchema.object()
    .description("Person information")
    .property("name", PropertySchema.string("Full name"))
    .property("age", PropertySchema.number("Age"))
    .property("active", PropertySchema.bool("Is active"))
    .property("status", PropertySchema.enumOf(
        "Account status",
        "active", "inactive", "pending"
    ))
    .required("name", "age")
    .build();
```
**Supported types in v0.3:**
- string
- number
- boolean
- enum (string with fixed values)

**Schema Validation**
Validate any JSON string against a schema.
```java
SchemaValidator validator = new SchemaValidator(schema);

ValidationResult result = validator.validate(json);

if (!result.isValid()) {
    System.out.println(result.formatErrors());
}
```
***ValidationResult exposes:***
- isValid()
- errors() → List<FieldError>
- formatErrors()

***Each FieldError includes:***
- fieldPath
- errorType
- expected
- received
- message

**Schema Enforcement**
SchemaEnforcer automatically retries the model until valid JSON is produced (or retries are exhausted).
```java
SchemaEnforcer enforcer =
    new SchemaEnforcer(model, schema, 3);

String json = enforcer.execute(
    "Extract person info from: Alice Smith is 30"
);
```
Internally:

LLM -> validate -> retry with errors -> repeat
If all retries fail, SchemaException is thrown.

**SchemaNode (Graph Integration)**
SchemaNode combines:

- ChatModel

- JSONSchema

- SchemaEnforcer

It acts as the boundary between text and structured data.

Signature (v0.3):

String → Map<String,Object>
Creating a SchemaNode:
```java
SchemaNode node = SchemaNode.builder()
    .model("gpt-4o-mini")
    .schema(schema)
    .memory("extractions")
    .build();
```
---

Public API (v0.3)
Prompts
- PromptTemplate.of(...)
- template.render(...)
- Variable.required(...)
- Variable.optional(...)

Schema
- JSONSchema.object()
- PropertySchema.string(...)
- PropertySchema.number(...)
- PropertySchema.bool(...)
- PropertySchema.enumOf(...)

Validation
- SchemaValidator.validate(...)
- ValidationResult
- FieldError
- Enforcement
- SchemaEnforcer.execute(...)
- SchemaException

Graph
- SchemaNode.builder()...
- SchemaNode.process(...)

---

**Migration from v0.2**

v0.3 is backward compatible.

You can still use:

model.chat(...)

---

**Mental Model**

PromptTemplate = reusable prompt

JSONSchema = output contract

SchemaEnforcer = retry loop

SchemaNode = graph boundary (text → data)

---

##Examples

**Example 1**

Customer Support Classifier

Goal: Classify support tickets with structured outputs

```java
import io.oxyjen.core.*;
import io.oxyjen.llm.*;
import io.oxyjen.llm.prompts.*;
import io.oxyjen.llm.schema.*;

public class SupportClassifier {

    public static void main(String[] args) {

        PromptTemplate prompt = PromptTemplate.of("""
            You are a customer support ticket classifier for {{company_name}}.

            Classify this support ticket:
            "{{ticket_message}}"

            Determine:
            - Priority (low, medium, high, critical)
            - Department (billing, technical, sales, general)
            - Customer sentiment (happy, neutral, frustrated, angry)
            - Brief summary

            Respond ONLY with valid JSON.
            """,
            Variable.required("company_name"),
            Variable.required("ticket_message")
        );

        JSONSchema schema = JSONSchema.object()
            .property("priority", PropertySchema.enumOf(
                "Ticket priority",
                "low", "medium", "high", "critical"
            ))
            .property("department", PropertySchema.enumOf(
                "Handling department",
                "billing", "technical", "sales", "general"
            ))
            .property("sentiment", PropertySchema.enumOf(
                "Customer emotion",
                "happy", "neutral", "frustrated", "angry"
            ))
            .property("summary", PropertySchema.string("Brief issue summary"))
            .required("priority", "department", "sentiment", "summary")
            .build();

        SchemaNode classifyNode = SchemaNode.builder()
            .model("gpt-4o-mini")
            .schema(schema)
            .memory("support-tickets")
            .build();

        Graph pipeline = GraphBuilder.named("support-classifier")
            .addNode(classifyNode)
            .build();

        NodeContext ctx = new NodeContext();
        Executor executor = new Executor();

        String ticket =
            "I was charged twice for my subscription! I want a refund NOW!";

        // Render prompt 
        String renderedPrompt =
            prompt.render(
                "company_name", "Acme Corp",
                "ticket_message", ticket
            );

        // Then send rendered prompt to SchemaNode
        Map<String,Object> result =
            executor.run(pipeline, renderedPrompt, ctx);

        System.out.println(result);
    }
}
```

**Example 2**

Data Extraction Pipeline

Goal: Extract structured data from unstructured text.

```java
import io.oxyjen.core.*;
import io.oxyjen.llm.*;
import io.oxyjen.llm.schema.*;

public class DataExtractor {
    
    public static void main(String[] args) {
        // Define schema for person data
        JSONSchema personSchema = JSONSchema.object()
            .property("name", PropertySchema.string("Full name"))
            .property("age", PropertySchema.number("Age in years"))
            .property("email", PropertySchema.string("Email address"))
            .property("phone", PropertySchema.string("Phone number"))
            .property("city", PropertySchema.string("City of residence"))
            .required("name")  // Only name is required
            .build();
        
        // Create model with fallback
        ChatModel model = LLMChain.builder()
            .primary("gpt-4o")
            .fallback("gpt-4o-mini")
            .retry(3)
            .timeout(Duration.ofSeconds(10))
            .build();
        
        // Create enforcer
        SchemaEnforcer enforcer = new SchemaEnforcer(model, personSchema);
        
        // Extract from different formats
        String[] inputs = {
            "John Smith is 35 years old, lives in NYC, email: john@example.com",
            "Name: Alice Johnson, Age: 28, San Francisco, (415) 555-0123",
            "Bob Williams, age 42, bob.w@company.com"
        };
        
        for (String input : inputs) {
            String json = enforcer.execute(
                "Extract person information from: " + input
            );
            System.out.println(json);
        }
        
        /*
        Output:
        {"name": "John Smith", "age": 35, "email": "john@example.com", "city": "NYC"}
        {"name": "Alice Johnson", "age": 28, "city": "San Francisco", "phone": "(415) 555-0123"}
        {"name": "Bob Williams", "age": 42, "email": "bob.w@company.com"}
        */
    }
}
```

# Jitter and Retry Cap

Jitter and Retry Cap are production-grade features that prevent cascading failures and unbounded waits when retrying failed LLM requests.

---

## The Problem

### Without Jitter: The Thundering Herd

When multiple requests fail simultaneously (for example during an API outage or rate limit), they retry at the same time:

Time 0s: 1000 requests fail simultaneously
Time 1s: 1000 requests retry simultaneously
Time 3s: 1000 requests retry simultaneously
Time 7s: 1000 requests retry simultaneously

Result: synchronized retry waves keep hammering the API, preventing recovery.

---

### Without Retry Cap: Unbounded Waits

Exponential backoff grows forever:

Attempt 1: 1s
Attempt 2: 2s
Attempt 3: 4s
Attempt 4: 8s
Attempt 5: 16s
Attempt 6: 32s
Attempt 7: 64s
Attempt 8: 128s


Result:

- users experience unacceptable delays  
- threads remain blocked  
- resources are wasted  

---

## The Solution

### Jitter: Randomize Retry Delays

Add randomness to spread retries across time.

With ±20% jitter:

Time 0.8–1.2s: ~200 requests retry
Time 1.0–1.4s: ~200 requests retry
Time 1.2–1.6s: ~200 requests retry
Time 1.4–1.8s: ~200 requests retry
Time 1.6–2.0s: ~200 requests retry

Result: smooth distributed load instead of synchronized spikes.

---

### Retry Cap: Bound Maximum Delay

Cap exponential backoff at a reasonable maximum.

With `maxBackoff = 10s`:

Attempt 1: 1s
Attempt 2: 2s
Attempt 3: 4s
Attempt 4: 8s
Attempt 5: 10s (capped)
Attempt 6: 10s
Attempt 7: 10s

Result: predictable wait times and better UX.

---

## Usage

### Recommended Defaults

```java
LLMChain chain = LLMChain.builder()
    .primary("gpt-4")
    .fallback("gpt-3.5-turbo")
    .retry(5)
    .exponentialBackoff()
    .maxBackoff(Duration.ofSeconds(10))
    .jitter(0.2)
    .build();
```
Behavior:

exponential delays (~1s, ~2s, ~4s, ~8s, ~10s)

each delay randomized ±20%

never exceeds 10 seconds

Production Configuration
```java
LLMChain chain = LLMChain.builder()
    .primary("gpt-4")
    .fallback("claude-3-sonnet")
    .fallback("gpt-3.5-turbo")
    .retry(7)
    .exponentialBackoff()
    .maxBackoff(Duration.ofSeconds(15))
    .jitter(0.3)
    .timeout(Duration.ofSeconds(30))
    .build();
```
Use case: critical workloads with bounded waits and aggressive retries.

Conservative Configuration
```java
LLMChain chain = LLMChain.builder()
    .primary("gpt-3.5-turbo")
    .retry(3)
    .exponentialBackoff()
    .maxBackoff(Duration.ofSeconds(5))
    .jitter(0.15)
    .build();
```
Use case: interactive applications.

No Jitter or Cap (v0.2 Behavior)
```java
LLMChain chain = LLMChain.builder()
    .primary("gpt-4")
    .retry(3)
    .exponentialBackoff()
    .build();
```
Result: deterministic exponential backoff with no upper bound.

Configuration Parameters
maxBackoff(Duration)
Sets maximum retry delay.

Internal Algorithm
```java
private long calculateBackoff(int attempt) {
    Duration base = exponentialBackoff
        ? Duration.ofSeconds(1L << (attempt - 1))
        : Duration.ofSeconds(1);

    if (maxBackoff != null && base.compareTo(maxBackoff) > 0) {
        base = maxBackoff;
    }

    if (jitterFactor > 0) {
        double multiplier = ThreadLocalRandom.current()
            .nextDouble(1.0 - jitterFactor, 1.0 + jitterFactor);

        base = Duration.ofMillis((long) (base.toMillis() * multiplier));
    }

    return base.toMillis();
}
```

Key points:
- exponential growth via 2^(attempt-1)
- cap applied first 
- jitter applied last
- ThreadLocalRandom used for efficiency

---
